{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/Users/donghua/spark-2.4.0-bin-hadoop2.7')\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession(SparkContext()).builder.master('local[2]').appName('Handson PySpark Chapter 5').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.warehouse.dir', '/user/hive/warehouse'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'local-1553755489097'),\n",
       " ('spark.driver.port', '51208'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.name', 'Handson PySpark Chapter 5'),\n",
       " ('spark.driver.host', '192.168.31.177'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.master', 'local[2]')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = 'http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz'\n",
    "localfile = '/tmp/kddcup.data_10_percent.gz'\n",
    "f = urllib.request.urlretrieve(url,localfile)\n",
    "\n",
    "raw_data = sc.textFile('file:///tmp/kddcup.data_10_percent.gz')\n",
    "csv = raw_data.map(lambda x: x.split(','))\n",
    "duration = raw_data.map(lambda x: [int(x[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "summary = Statistics.colStats(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06611054995637812"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.mean()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494021"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '181', '5450'], ['0', '239', '486']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = csv.map(lambda x: [x[0],x[4],x[5]])\n",
    "metrics.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.01419628,  0.29918926],\n",
       "       [ 0.01419628,  1.        , -0.16793059],\n",
       "       [ 0.29918926, -0.16793059,  1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(metrics, method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.25823027e-03,  5.43953448e-03],\n",
       "       [ 4.25823027e-03,  1.00000000e+00, -1.59677215e-06],\n",
       "       [ 5.43953448e-03, -1.59677215e-06,  1.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(metrics, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 4 \n",
      "statistic = 0.5852136752136753 \n",
      "pValue = 0.9646925263439344 \n",
      "No presumption against null hypothesis: observed follows the same distribution as expected..\n"
     ]
    }
   ],
   "source": [
    "visitors_freq = Vectors.dense(0.13, 0.61, 0.8, 0.5, 0.3)\n",
    "print(Statistics.chiSqTest(visitors_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 4 \n",
      "statistic = 22.469462151394424 \n",
      "pValue = 1.6158934330234853E-4 \n",
      "Very strong presumption against null hypothesis: observed follows the same distribution as expected..\n"
     ]
    }
   ],
   "source": [
    "visitors_freq = Vectors.dense(0.13, 0.61, 0.8, 0.5, 8)\n",
    "print(Statistics.chiSqTest(visitors_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 494020 \n",
      "statistic = 2041502.1434188513 \n",
      "pValue = 0.0 \n",
      "Very strong presumption against null hypothesis: observed follows the same distribution as expected..\n"
     ]
    }
   ],
   "source": [
    "print(Statistics.chiSqTest(duration.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
